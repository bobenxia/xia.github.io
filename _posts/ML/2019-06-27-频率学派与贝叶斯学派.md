---
layout: post
title: 频率学派与贝叶斯学派
category: ML
tags: ML
keywords: 频率学派 贝叶斯学派
description:
---

- 频率学派 - Frequentist - Maximum Likelihood Estimation (MLE，最大似然估计)

- 贝叶斯学派 - Bayesian - Maximum A Posteriori (MAP，最大后验估计)

频率学派认为世界是确定的，有一个本体，这个本体的真值是不变的，我们的目标就是要找到这个真值或真值所在的范围；而贝叶斯学派认为世界是不确定的，人们对世界先有一个预判，而后通过观测数据对这个预判做调整，我们的目标是要找到最优的描述这个世界的概率分布。

在对事物建模时，用 $\theta$ 表示模型的参数，请注意，解决问题的本质就是求 $\theta$。那么：

### 频率学派

存在唯一真值θ。举一个简单直观的例子—抛硬币，我们用 P(head) 来表示硬币的 bias。抛一枚硬币 100 次，有 20次 正面朝上，要估计抛硬币正面朝上的 bias $P(head)=\theta$。在频率学派来看，$\theta= \frac {20} {100} = 0.2$，很直观。

当数据量趋于无穷时，这种方法能给出精准的估计；然而缺乏数据时则可能产生严重的偏差。例如，对于一枚均匀硬币，即 $\theta = 0.5$，抛掷 5 次，出现 5 次正面 (这种情况出现的概率是 $\frac{1}{2^{5}} = 3.125%$)，频率学派会直接估计这枚硬币 $\theta = 1$，出现严重错误。

### 贝叶斯学派

$\theta$ 是一个随机变量，符合一定的概率分布。在贝叶斯学派里有两大输入和一大输出，输入是先验 (prior) 和似然 (likelihood)，输出是后验 (posterior)。

先验，即 $P (\theta)$，指的是在没有观测到任何数据时对 $\theta$ 的预先判断，例如给我一个硬币，一种可行的先验是认为这个硬币有很大的概率是均匀的，有较小的概率是是不均匀的；似然，即 $P ( X \mid \theta )$，是假设 $\theta$ 已知后我们观察到的数据应该是什么样子的；后验，即$P ( \theta \mid X )$，是最终的参数分布。

贝叶斯估计的基础是贝叶斯公式，如下：

$$
P ( \theta \mid X ) = \frac { P ( X \mid \theta ) \times P ( \theta ) } { P ( X ) }
$$

同样是抛硬币的例子，对一枚均匀硬币抛 5 次得到 5 次正面，如果先验认为大概率下这个硬币是均匀的 (例如最大值取在 0.5 处的 $\beta$ 分布)，那么 P(head)，即 $P ( \theta \mid X )$，是一个分布，最大值会介于 0.5~1 之间，而不是武断的 $\theta = 1$。

这里有两点值得注意的地方：

随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小

如果先验是均匀分布，则贝叶斯方法等价于频率方法。因为直观上来讲，先验是均匀分布本质上表示对事物没有任何预判。

### MLE - 最大似然估计

Maximum Likelihood Estimation, MLE 是**频率学派**常用的估计方法！

假设数据 $X _ { 1 } , X _ { 2 } , \ldots , X _ { n }$ 是i.i.d.的一组抽样，$X = \left( X _ { 1 } , X _ { 2 } , \ldots , X _ { n } \right)$ 。其中 i.i.d. 表示 Independent and identical distribution，独立同分布。那么 MLE 对 $\theta$ 的估计方法可以如下推导：

<div>
$$
\begin{aligned} \hat { \theta } _ { \mathrm { MLE } } & = \arg \max P ( X ; \theta ) \\ & = \arg \max P \left( x _ { 1 } ; \theta \right) P \left( x _ { 2 } ; \theta \right) \cdots P \left( x _ { n } ; \theta \right) \\ & = \arg \max \log \prod _ { i = 1 } ^ { n } P \left( x _ { i } ; \theta \right) \\ & = \arg \max \sum _ { i = 1 } ^ { n } \log P \left( x _ { i } ; \theta \right) \\ & = \arg \min - \sum _ { i = 1 } ^ { n } \log P \left( x _ { i } ; \theta \right) \end{aligned}
$$
</div>

最后这一行所优化的函数被称为 Negative Log Likelihood (NLL)！

我们经常在不经意间使用 MLE，例如

上文中关于频率学派求硬币概率的例子，其方法其实本质是由优化 NLL 得出。本文末尾附录中给出了具体的原因。

给定一些数据，求对应的高斯分布时，我们经常会算这些数据点的均值和方差然后带入到高斯分布的公式，其理论依据是优化 NLL。

深度学习做分类任务时所用的 cross entropy loss，其本质也是 MLE

### MAP - 最大后验估计

Maximum A Posteriori, MAP 是**贝叶斯学派**常用的估计方法！

假设数据 $X _ { 1 } , X _ { 2 } , \ldots , X _ { n }$ 是i.i.d.的一组抽样，$X = \left( X _ { 1 } , X _ { 2 } , \ldots , X _ { n } \right)$ 。那么 MAP 对 $\theta$ 的估计方法可以如下推导：

<div>
$$
\begin{aligned} \hat { \theta } _ { \mathrm { MAP } } & = \arg \max P ( \theta \mid X ) \\ & = \arg \min - \log P ( \theta \mid X ) \\ & = \arg \min - \log P ( X \mid \theta ) - \log P ( \theta ) + \log P ( X ) \\ & = \arg \min - \log P ( X \mid \theta ) - \log P ( \theta ) \end{aligned}
$$
</div>

其中，第二行到第三行使用了贝叶斯定理，第三行到第四行 $P ( X )$ 可以丢掉因为与 $\theta$ 无关。注意 $- \log P ( X \mid \theta )$ 其实就是 NLL，所以 MLE 和 MAP 在优化时的不同就是在于先验项$- \log P (\theta )$。好的，那现在我们来研究一下这个先验项，假定先验是一个高斯分布，即

$$
P ( \theta ) = \text { constant } \times e ^ { - \frac { \theta ^ { 2 } } { 2 \sigma ^ { 2 } } }
$$

那么，

$$
-\log P ( \theta ) = \text { constant } + \frac { \theta ^ { 2 } } { 2 \sigma ^ { 2 } }
$$

至此，一件神奇的事情发生了 — 在 MAP 中使用一个高斯分布的先验等价于在 MLE 中采用 L2 的 regularizaton!

### 附录

**为什么说频率学派求硬币概率的算法本质是在优化 NLL？**

因为抛硬币可以表示为参数为 $\theta$ 的伯努利分布，即：

<div>
$$
P \left( x _ { i } ; \theta \right) = \left\{ \begin{array} { l l } { \theta } & { x _ { i } = 1 } \\ { 1 - \theta } & { x _ { i } = 0 } \end{array} = \theta ^ { x _ { i } } ( 1 - \theta ) ^ { 1 - x _ { i } } \right.
$$
</div>

其中 $x_i= 1$ 表示第 i 次抛出正面。那么，

$$
\mathrm { NLL } = - \sum _ { i = 1 } ^ { n } \log P \left( x _ { i } ; \theta \right) = - \sum _ { i = 1 } ^ { n } \log \theta ^ { x _ { i } } ( 1 - \theta ) ^ { 1 - x _ { i } }
$$

求导数并使其等于零，得到

$$
\mathrm { NLL } ^ { \prime } = - \sum _ { i = 1 } ^ { n } \left( \frac { x _ { i } } { \theta } + \left( 1 - x _ { i } \right) \frac { - 1 } { 1 - \theta } \right) = 0
$$

即 $\hat { \theta } = \frac { \sum _ { i = 1 } ^ { n } x _ { i } } { n }$，也就是出现正面的次数除以总共的抛掷次数。